\documentclass[titlepage, a4paper, 11pt]{scrartcl}

%too much whitespace otherwise
\usepackage[left=30mm,top=26mm,right=26mm,bottom=15mm]{geometry}

% deutsche Übersetzungen
%\usepackage[ngerman]{babel}
% Grafik Pakete
\usepackage{graphicx,hyperref,amssymb}
% Ordner für Grafiken
\graphicspath{ {./images/} }
% Pakete für Formatierung der Grafiken
\usepackage{wrapfig}
\usepackage{float}
% deutsches Encoding (Umlaute)
\usepackage[utf8]{inputenc}
% für Grad Symbol
\usepackage{textcomp}

% Header and Footer
\usepackage{fancyhdr}

%image grid
\usepackage{graphicx}
\usepackage{subfig}

\usepackage{multicol}

%harvard cite style - use this: \citep{key}
\usepackage{natbib}
\setcitestyle{authoryear,open={(},close={)}}

\pagestyle{fancy}
\fancyhf{}
\rhead{Lückert, Neudecker}
\lhead{Kalman-filter development - literature research}
 
\begin{document}

\section{Research Goals}

Primarily we are looking for related work in the field of kalman filtering in billiards, to inform ourselves about the current progress of research and state-of-the-art solutions.

Secondly our goal with the literature research is to find sources of information which complements our expertise. 

While writing our proposal we identified five aspects where we lack sufficient expertise.
These are in particular:

\paragraph{Design of experiments}

As outlined in the research proposal we are going to develop our ideas in a simulation. Therefore it is efficient to design the experimental part in advance.
This means that we are not going to use a trial-and-error approach but instead invest some time to think about possible outcomes and how to achieve these by 
altering different parameters in particular and develop a deeper understanding of their behavior.

\paragraph{Gradient descent algorithms}

Since there exist a huge number of different numerical and analytical ways to solve a gradient descent problem it will save time to evaluate the best
suitable algorithm prior to implementation to avoid unnecessary work.

\paragraph{Efficient implementation of algorithms}

This is especially important since our algorithm is supposed to work in realtime.
Therefore any delay induced by inefficient code is unacceptable.

\paragraph{openCV best practices}

The analysis of the original footage is made by openCV. Since this library offers a wide variety of different approaches to isolate objecs in videofootage,
it is evaluate the best option.

\paragraph{Measure and comparison of quantifiable data}

The results in our research will be mainly represented by numbers. To create a better understanding of these numbers and how they interact it is a good approach to 
evaluate different methods of putting numbers in context to one another and which scales and graphs are the quasi standard across the research community.


\section{Source of Information}

For the research regarding \textit{state-of-the-art solutions} and \textit{efficient implementation of algorithms and openCV best practices} it is the best option to look for recent papers since these topics are currently
subjects where a certain number of people are working on. Therefore the following archives offer a good starting point to search for up-to-date papers:

\begin{enumerate}
    \item IEEE online database
    \item arXiv.org
    \item ACM Digital Library
    \item Google Scholar
\end{enumerate}

The Topics \textit{statistical experimental design and measure and comparison of quantifiable data} are already established in the scientific community.
Therefore it is the best approach to consult the latest literature in these particular fields. In our case this can be done to a certain extent with the HIBS database
and online services or with actual books in the library.

\textit{The efficient implementation of algorithms} is less of a scientific problem but of a code-optimization. Hence reading blogs of skilled programmers or threads on
\textit{Stackoverflow} seems as the most reasonable approach.

\section{Criteria for eligible sources}

The general criteria for any sources are mostly common sense:

\begin{itemize}
    \item credibility and plausibility
    \item a certain standard of quality
    \item integrity
\end{itemize}

These criteria might seem overly cautious in case the source is a book written by any member of the scientific community. However in the case of short paper or online blog
the author of that particular source might not be as credible. Therefore a higher level of scrutiny with the informations provided is necessary.

Furthermore since the sources might be cited in a paper or dissertation they have to be scientificly quotable. This is expecially true to protect the resulting work against 
accusations of plagiarism.

As already pointed out in the previous section some topics are more subject to change due to present research activities
and must therefore reflect the most recent state of research. 

Another important aspect is especially the case with non-scientific online ressources as blogs and the previously mentioned
\textit{Stackoverflow}. Since these sources are also subject to change, it is important to keep track of the particular
version of the ressource to prevent confusion in case the ressources changes.

\section{Sources for our research}

\subsection{Related Work}

Jong-Yun Kim and Tae-Yong Kim \cite{kim} developed a method to provide robust tracking of a soccer ball. 
They provide a solution for the problem for the case that the soccer ball might be occluded by the player at any given time,
which results in a diminished tracking accuracy. 
In this case they used the velocity vector of the player to substitute for the ball presuming that the ball moves in the same direction as the player does.

Jia et.al. \cite{jia} conducted research in the trajectory of pool balls, which helped us to decide which kalman model is the most suitable.

Shiuh et.al. \cite{shiuh} provided a good starting point how to create a tracking algorithm for pool balls. They also developed an algorithm to track occluded objects using an adaptive kalman filter.
In this case they used to threshold in order to determine whether the object can still be reliably tracked. If this isn't the case the filter will rely only on predicted values until the object can be tracked reliably again.

Salzmann and Urtasun \cite{salzmann} proposed a more general approach for tracking. 
They were able to recreate a highly accurate tracking from a noisy picture based on newtons 2nd law and markov models.
Using different constraints and presumptions they were even able to extract physical parameters like friction and trajectories.

Mohamed and Schwarz \cite{schwarz} are using partly the same approach as we do to improve the results created by INS/GPS\footnote{Inertial Navigation System / Global Positioning System} Systems.
However their approach only targets the 'Q' and 'R' parameters of the filter.

Sarkka and Nummenmaa \cite{sarkka} created an adaptive kalman implementation which adapts itself to time-varying noise parameters. Since our input data is constant in this regard,
we decided to simulate for the optimal filter parametrization instead of relying on the filter to adapt itself.

Gabdulkhakova and Kropatsch \cite{kropatsch} use a kalman filter to create a video analysis tool for snooker game broadcasting.

\subsection{Design of experiments}

To get a general sense of how statistical experimental design works these Books provide a good introduction into this topic: \citep{siebertz2017statistische} and \citep{retzlaff1978statistische}.
Both books are available at our local Library.

A more practical approach is outlined in the articles \citep{hoevelmann1993statistische} and \citep{schweitzer1992off}.

\citep{siebertz2017doe} is a good source of examples to put everything in context.

\subsection{Gradient  descent  algorithms}

Although the gradient descent method is often used in Machine Learning to optimize parameters in neural networks, we can use it to solve our optimization problem.
The articles \citep{ketkar2017deep} and \citep{marti2005stochastic} provides an introduction to the optimization problem with GD methods whereas \citep{marti2005stochastic} gives an overview with more advanced methods.

\citep{bishop2006pattern} is a very famous book for more advanced topics. Since we've got a basic understanding of how to implement GD in our simulation, we might consider using 
some advanced techniques from this book. This might prove especially useful because the normal gradient descent method can only find local minimas.

\subsection{Efficient implementation  of  algorithms}

There exist a few different approaches to optimize an algorithm for fast execution. These are in particular paralelization and compiletime optimization.

Since our optimized filter will highly rely on vector and matrix operations, there is a big potencial for all these optimizations. However since we lack experience in
writing special code like this, we have to make us familiar with the basics of such coding.

For paralelization through parallel hardware we could use openCL. An comprehensive introduction is provided by \citep{trevett2013opencl} and \citep{tompson2012introduction}.

An introduction in compiletime optimization is provided by \citep{hohenauer2006retargetable} and introduction on how to use the new AVX instruction on Intel Processors is given by \citep{cornea2015intel}.


\subsection{openCV best practices}

With the article \citep{janku2016comparison} we can get an overview and comparison of different detection algorithms for the OpenCV framework.

The article \citep{gao2018design} gives an insight on how to design a multi-object detection system for billiards in openCV, which perfectly fits our research case.

The conference paper \citep{gabel2018jetson} uses neural networks in conjunction with openCV to detect balls.
This approach aims for an efficient re-training of neural networks. This is useful for our research, because we can easily adopt the algorithm to different pool environments and do not have to manually adjust the ball detection.

The thesis \citep{schmidt2016measuring} focuses on performance optimization for speed estimation of balls with openCV on mobile devices. This is useful for our research, because we want to achieve real-time tracking and eventually port the application to mobile devices.

\subsection{Measure and comparison of quantifiable data}

The standard method to visualize the mean square error of Kalman-filters are 2D plots,
which can be seen in \citep{8993001} and \citep{1165091}. The y-axis describes the MSE and x-axis the observed parameter. 

\bibliography{literature} 
\bibliographystyle{abbrvnat}


\end{document}